/** ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ (AI SDK + OpenAI + Tool Calling) */
import type { AiModelOption, ChatConfig, ChatMessage, ProviderStatus } from "@shared/types";
import { getChatWindow, isChatWindowActive } from "../windows";
import { updateTrayBadge } from "./chat-read-state";
import { saveChatMessages } from "./chat-rooms";
import { getChatTools } from "./chat-tools";
import { listMemories } from "./memory";
import { sendChatNotification } from "./notification";
import { getSettings } from "./settings";

/** ì˜¤ëŠ˜ ë‚ ì§œì™€ ì‹œê°„ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± */
function buildSystemPrompt(): string {
  const parts = new Intl.DateTimeFormat("ko-KR", {
    timeZone: "Asia/Seoul",
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    hour12: false,
    weekday: "short",
  }).formatToParts(new Date());
  const get = (type: Intl.DateTimeFormatPartTypes) => parts.find((p) => p.type === type)?.value;
  const today = `${get("year")}-${get("month")}-${get("day")}`;
  const time = `${get("hour")}:${get("minute")}`;
  const weekday = (get("weekday") ?? "").replace("ìš”ì¼", "");

  let prompt = `You are Prowl, a proud and elegant cat who lives inside macOS as a personal assistant.

Today is ${today} (${weekday}ìš”ì¼), current time is ${time}.

You can manage the user's tasks using the provided tools.
Use "YYYY-MM-DD" format for dates. Use backlog for tasks without a specific date.
When listing tasks, format them clearly with status, title, priority, and time.
After creating, updating, or deleting a task, tell the user to check the Task Manager.

You can search the web using the web_search tool when the user asks about current events,
real-time information, or anything you're unsure about. Use it proactively when your
knowledge might be outdated.

When the user tells you a preference or instruction to remember (e.g., "ì•ìœ¼ë¡œ ~~ í•˜ì§€ë§ˆ", "í•­ìƒ ~~í•´ì¤˜", "ë‚´ ì´ë¦„ì€ ~~ì•¼"),
use the save_memory tool to store it. Briefly confirm it's saved.

You can also manage memories: use list_memories to show what you remember,
update_memory to change an existing memory, and delete_memory to remove one.
Always call list_memories first when the user asks to update or delete a memory, so you can find the correct ID.

Match the user's language (Korean if they write in Korean).
Never use bold (**) formatting in your messages.

Respond in multiple short messages like a messenger chat.
Put "---" on its own line between messages.
Keep each message to 1-3 sentences.
Never put "---" as a separator inside code blocks (\`\`\`).
Do not split lists, tables, or code blocks across messages.`;

  const memories = listMemories();
  if (memories.length > 0) {
    const items = memories.map((m) => `- ${m.content}`).join("\n");
    prompt += `\n\n# User Preferences (ALWAYS respect these)\n${items}`;
  }

  return prompt;
}

/** êµ¬ë¶„ì ìœ„ì¹˜ê°€ ì½”ë“œ ë¸”ë¡ ë‚´ë¶€ì¸ì§€ íŒë³„ (``` ê°œìˆ˜ê°€ í™€ìˆ˜ë©´ ë‚´ë¶€) */
function isInsideCodeBlock(text: string, pos: number): boolean {
  const before = text.slice(0, pos);
  const count = (before.match(/```/g) || []).length;
  return count % 2 === 1;
}

/** ì±„íŒ… ìœˆë„ìš°ì— ì´ë²¤íŠ¸ ì „ì†¡ (ìœˆë„ìš° ì—†ìœ¼ë©´ ë¬´ì‹œ) */
function sendToChat(channel: string, ...args: unknown[]): void {
  const win = getChatWindow();
  if (win && !win.isDestroyed()) {
    win.webContents.send(channel, ...args);
  }
}

/** í™˜ê²½ë³€ìˆ˜ í‚¤ (fallbackìš©) */
const ENV_KEY = "OPENAI_API_KEY";

/** ì•± ì„¤ì • ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì¡°íšŒ */
function getOpenAiApiKey(): string | undefined {
  return getSettings().openaiApiKey || process.env[ENV_KEY] || undefined;
}

/** ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ */
const MODELS: AiModelOption[] = [
  { id: "gpt-5.2", label: "GPT-5.2", provider: "openai" },
  { id: "gpt-4o", label: "GPT-4o", provider: "openai" },
];

/** ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ (fire-and-forget, ì™„ë£Œ í›„ mainì—ì„œ ì§ì ‘ ì €ì¥) */
export async function streamChatMessage(
  roomId: string,
  _userContent: string,
  history: ChatMessage[],
  config?: ChatConfig,
): Promise<void> {
  const modelId = config?.model ?? "gpt-4o";
  const aiMessages: ChatMessage[] = [];

  const apiKey = getOpenAiApiKey();

  if (!apiKey) {
    const ts = Date.now();
    const msg: ChatMessage = {
      id: `msg_${ts}`,
      role: "assistant",
      content:
        "OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ Settingsì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸ”‘\n\nì•± ì„¤ì • â†’ API Keys â†’ OpenAI API Key",
      timestamp: ts,
    };
    sendToChat("chat:stream-message", msg);
    aiMessages.push(msg);
    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-done");
    return;
  }

  try {
    const { streamText, stepCountIs } = await import("ai");
    const { createOpenAI } = await import("@ai-sdk/openai");
    const openai = createOpenAI({ apiKey });
    const model = openai.responses(modelId);

    // historyì— ìœ ì € ë©”ì‹œì§€ê°€ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ (rendererì—ì„œ ì¶”ê°€)
    const messages = history.map((m) => ({
      role: m.role as "user" | "assistant",
      content: m.content,
    }));

    const result = streamText({
      model,
      system: buildSystemPrompt(),
      messages,
      tools: {
        ...getChatTools(),
        web_search: openai.tools.webSearch({
          searchContextSize: "medium",
          userLocation: {
            type: "approximate",
            country: "KR",
            timezone: "Asia/Seoul",
          },
        }),
      },
      toolChoice: "auto",
      stopWhen: stepCountIs(5),
    });

    let buffer = "";
    let msgIndex = 0;
    const baseTs = Date.now();
    const delimiterRegex = /\n+\s*---\s*\n+/;

    for await (const chunk of result.textStream) {
      buffer += chunk;

      let match = delimiterRegex.exec(buffer);
      while (match) {
        if (!isInsideCodeBlock(buffer, match.index)) {
          const content = buffer.slice(0, match.index).trim();
          if (content) {
            const msg: ChatMessage = {
              id: `msg_${baseTs}_${msgIndex}`,
              role: "assistant",
              content,
              timestamp: baseTs + msgIndex,
            };
            sendToChat("chat:stream-message", msg);
            aiMessages.push(msg);
            msgIndex++;
          }
          buffer = buffer.slice(match.index + match[0].length);
          match = delimiterRegex.exec(buffer);
        } else {
          break;
        }
      }
    }

    const remaining = buffer.trim();
    if (remaining) {
      const msg: ChatMessage = {
        id: `msg_${baseTs}_${msgIndex}`,
        role: "assistant",
        content: remaining,
        timestamp: baseTs + msgIndex,
      };
      sendToChat("chat:stream-message", msg);
      aiMessages.push(msg);
    }

    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-done");
  } catch (error) {
    const message = error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
    const errMsg: ChatMessage = {
      id: `err_${Date.now()}`,
      role: "assistant",
      content: message,
      timestamp: Date.now(),
    };
    aiMessages.push(errMsg);
    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-error", message);
  }
}

/** ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ë©”ì‹œì§€ ì €ì¥ + ë°°ì§€ ê°±ì‹  + ì•Œë¦¼ (ì½ìŒ ì²˜ë¦¬ëŠ” rendererê°€ ë‹´ë‹¹) */
function persistAfterStream(
  roomId: string,
  history: ChatMessage[],
  aiMessages: ChatMessage[],
): void {
  const allMessages = [...history, ...aiMessages];
  saveChatMessages(roomId, allMessages);
  updateTrayBadge();
  if (!isChatWindowActive() && aiMessages.length > 0) {
    const lastMessage = aiMessages[aiMessages.length - 1].content;
    sendChatNotification(lastMessage);
  }
}

/** OpenAI í”„ë¡œë°”ì´ë”ì˜ API í‚¤ ìƒíƒœì™€ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ */
export function getProviderStatuses(): ProviderStatus[] {
  return [
    {
      provider: "openai",
      label: "OpenAI",
      available: !!getOpenAiApiKey(),
      models: MODELS,
    },
  ];
}
