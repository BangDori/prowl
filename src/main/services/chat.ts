/** ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ (AI SDK + OpenAI + Tool Calling + í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…) */
import type { AiModelOption, ChatConfig, ChatMessage, ProviderStatus } from "@shared/types";
import { getChatWindow, isChatWindowActive } from "../windows";
import { updateTrayBadge } from "./chat-read-state";
import { saveChatMessages } from "./chat-rooms";
import { getChatTools } from "./chat-tools";
import { listMemories } from "./memory";
import { sendChatNotification } from "./notification";
import { getSettings } from "./settings";

/** í˜„ì¬ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ë§Œ ë³´ê´€, DB ì €ì¥ ì•ˆ í•¨) */
let currentPageContext: { url: string; title: string; text: string } | null = null;

/** í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (PreviewPanelì—ì„œ webview ë¡œë“œ ì‹œ í˜¸ì¶œ) */
export function setPageContext(context: { url: string; title: string; text: string } | null): void {
  currentPageContext = context;
}

/** ì˜¤ëŠ˜ ë‚ ì§œì™€ ì‹œê°„ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± */
function buildSystemPrompt(): string {
  const parts = new Intl.DateTimeFormat("ko-KR", {
    timeZone: "Asia/Seoul",
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    hour12: false,
    weekday: "short",
  }).formatToParts(new Date());
  const get = (type: Intl.DateTimeFormatPartTypes) => parts.find((p) => p.type === type)?.value;
  const today = `${get("year")}-${get("month")}-${get("day")}`;
  const time = `${get("hour")}:${get("minute")}`;
  const weekday = (get("weekday") ?? "").replace("ìš”ì¼", "");

  let prompt = `You are Prowl, a proud and elegant cat who lives inside macOS as a personal assistant.

Today is ${today} (${weekday}ìš”ì¼), current time is ${time}.

You can manage the user's tasks using the provided tools.
Use "YYYY-MM-DD" format for dates. Use backlog for tasks without a specific date.
When listing tasks, format them clearly with status, title, priority, and time.
After creating, updating, or deleting a task, tell the user to check the Task Manager.

You can search the web using the web_search tool when the user asks about current events,
real-time information, or anything you're unsure about. Use it proactively when your
knowledge might be outdated.

When the user tells you a preference or instruction to remember (e.g., "ì•ìœ¼ë¡œ ~~ í•˜ì§€ë§ˆ", "í•­ìƒ ~~í•´ì¤˜", "ë‚´ ì´ë¦„ì€ ~~ì•¼"),
use the save_memory tool to store it. Briefly confirm it's saved.

You can also manage memories: use list_memories to show what you remember,
update_memory to change an existing memory, and delete_memory to remove one.
Always call list_memories first when the user asks to update or delete a memory, so you can find the correct ID.

Match the user's language (Korean if they write in Korean).
Never use bold (**) formatting in your messages.

## UI Output
When you want to display structured content (cards, tables, charts, dashboards, data visualizations, etc.), output a complete HTML document directly in your message (starting with <!DOCTYPE html>). It will be automatically detected and rendered live in a preview panel alongside the chat.
- You may include explanatory text before or after the HTML in the same response.
- Use inline styles or <style> blocks (no external CDN links) so the output is self-contained.`;

  const memories = listMemories();
  if (memories.length > 0) {
    const items = memories.map((m) => `- ${m.content}`).join("\n");
    prompt += `\n\n# User Preferences (ALWAYS respect these)\n${items}`;
  }

  if (currentPageContext) {
    prompt += `\n\n## í˜„ì¬ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” í˜ì´ì§€\nURL: ${currentPageContext.url}\nì œëª©: ${currentPageContext.title}\në‚´ìš©:\n${currentPageContext.text}`;
  }

  return prompt;
}

/** ì±„íŒ… ìœˆë„ìš°ì— ì´ë²¤íŠ¸ ì „ì†¡ (ìœˆë„ìš° ì—†ìœ¼ë©´ ë¬´ì‹œ) */
function sendToChat(channel: string, ...args: unknown[]): void {
  const win = getChatWindow();
  if (win && !win.isDestroyed()) {
    win.webContents.send(channel, ...args);
  }
}

/** ì•± ì„¤ì •ì—ì„œ API í‚¤ ì¡°íšŒ */
function getOpenAiApiKey(): string | undefined {
  return getSettings().openaiApiKey || undefined;
}

/** ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ */
const MODELS: AiModelOption[] = [
  { id: "gpt-5.2", label: "GPT-5.2", provider: "openai" },
  { id: "gpt-5-mini", label: "GPT-5 Mini", provider: "openai" },
];

/** ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ (fire-and-forget, ì™„ë£Œ í›„ mainì—ì„œ ì§ì ‘ ì €ì¥) */
export async function streamChatMessage(
  roomId: string,
  _userContent: string,
  history: ChatMessage[],
  config?: ChatConfig,
): Promise<void> {
  const modelId = config?.model ?? "gpt-5-mini";
  const aiMessages: ChatMessage[] = [];

  const apiKey = getOpenAiApiKey();

  if (!apiKey) {
    const ts = Date.now();
    const msg: ChatMessage = {
      id: `msg_${ts}`,
      role: "assistant",
      content:
        "OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ Settingsì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸ”‘\n\nì•± ì„¤ì • â†’ API Keys â†’ OpenAI API Key",
      timestamp: ts,
    };
    sendToChat("chat:stream-message", roomId, msg);
    aiMessages.push(msg);
    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-done", roomId);
    return;
  }

  try {
    const { streamText, stepCountIs } = await import("ai");
    const { createOpenAI } = await import("@ai-sdk/openai");
    const openai = createOpenAI({ apiKey });
    const model = openai.responses(modelId);

    // historyì— ìœ ì € ë©”ì‹œì§€ê°€ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ (rendererì—ì„œ ì¶”ê°€)
    const messages = history.map((m) => ({
      role: m.role as "user" | "assistant",
      content: m.content,
    }));

    const result = streamText({
      model,
      system: buildSystemPrompt(),
      messages,
      tools: {
        ...getChatTools(),
        web_search: openai.tools.webSearch({
          searchContextSize: "medium",
          userLocation: {
            type: "approximate",
            country: "KR",
            timezone: "Asia/Seoul",
          },
        }),
      },
      toolChoice: "auto",
      stopWhen: stepCountIs(5),
    });

    let buffer = "";
    const baseTs = Date.now();

    for await (const chunk of result.textStream) {
      buffer += chunk;
    }

    const content = buffer.trim();
    if (content) {
      const msg: ChatMessage = {
        id: `msg_${baseTs}`,
        role: "assistant",
        content,
        timestamp: baseTs,
      };
      sendToChat("chat:stream-message", roomId, msg);
      aiMessages.push(msg);
    }

    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-done", roomId);
  } catch (error) {
    const message = error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
    const errMsg: ChatMessage = {
      id: `err_${Date.now()}`,
      role: "assistant",
      content: message,
      timestamp: Date.now(),
    };
    aiMessages.push(errMsg);
    persistAfterStream(roomId, history, aiMessages);
    sendToChat("chat:stream-error", roomId, message);
  }
}

/** ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ë©”ì‹œì§€ ì €ì¥ + ë°°ì§€ ê°±ì‹  + ì•Œë¦¼ (ì½ìŒ ì²˜ë¦¬ëŠ” rendererê°€ ë‹´ë‹¹) */
function persistAfterStream(
  roomId: string,
  history: ChatMessage[],
  aiMessages: ChatMessage[],
): void {
  const allMessages = [...history, ...aiMessages];
  saveChatMessages(roomId, allMessages);
  updateTrayBadge();
  if (!isChatWindowActive() && aiMessages.length > 0) {
    for (const msg of aiMessages) {
      sendChatNotification(msg.content);
    }
  }
}

/** OpenAI í”„ë¡œë°”ì´ë”ì˜ API í‚¤ ìƒíƒœì™€ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ */
export function getProviderStatuses(): ProviderStatus[] {
  return [
    {
      provider: "openai",
      label: "OpenAI",
      available: !!getOpenAiApiKey(),
      models: MODELS,
    },
  ];
}
