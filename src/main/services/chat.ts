/** ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ì„œë¹„ìŠ¤ (AI SDK + OpenAI + Tool Calling) */
import type {
  AiModelOption,
  ChatConfig,
  ChatMessage,
  ChatSendResult,
  ProviderStatus,
} from "@shared/types";
import { getChatTools } from "./chat-tools";

/** ì˜¤ëŠ˜ ë‚ ì§œì™€ ì‹œê°„ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± */
function buildSystemPrompt(): string {
  const now = new Date();
  const today = now.toISOString().slice(0, 10);
  const time = now.toTimeString().slice(0, 5);
  const weekday = ["ì¼", "ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† "][now.getDay()];
  return `You are Prowl, a helpful macOS assistant that manages tasks and answers questions.
Today is ${today} (${weekday}ìš”ì¼), current time is ${time}.
You can manage the user's tasks using the provided tools.
Use "YYYY-MM-DD" format for dates. Use backlog for tasks without a specific date.
When listing tasks, format them clearly with status, title, priority, and time.
After creating, updating, or deleting a task, tell the user to check the Task Manager (Cmd+Shift+O).
Respond concisely. Use Korean if the user writes in Korean.`;
}

/** í™˜ê²½ë³€ìˆ˜ í‚¤ */
const ENV_KEY = "OPENAI_API_KEY";

/** ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ */
const MODELS: AiModelOption[] = [
  { id: "gpt-5.2", label: "GPT-5.2", provider: "openai" },
  { id: "gpt-4o", label: "GPT-4o", provider: "openai" },
];

/** API í‚¤ ë¯¸ë“±ë¡ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„± */
function createApiKeyGuideMessage(): ChatSendResult {
  return {
    success: true,
    message: {
      id: `msg_${Date.now()}`,
      role: "assistant",
      content: `OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ${ENV_KEY} í™˜ê²½ë³€ìˆ˜ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš” ğŸ”‘\n\ní„°ë¯¸ë„ì—ì„œ:\nexport ${ENV_KEY}=your-api-key\n\në˜ëŠ” ~/.zshrcì— ì¶”ê°€í•˜ë©´ ì˜êµ¬ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.`,
      timestamp: Date.now(),
    },
  };
}

export async function sendChatMessage(
  userContent: string,
  history: ChatMessage[],
  config?: ChatConfig,
): Promise<ChatSendResult> {
  const modelId = config?.model ?? "gpt-4o";

  if (!process.env[ENV_KEY]) {
    return createApiKeyGuideMessage();
  }

  try {
    const { generateText, stepCountIs } = await import("ai");
    const { openai } = await import("@ai-sdk/openai");
    const model = openai.responses(modelId);

    const messages = history.map((m) => ({
      role: m.role as "user" | "assistant",
      content: m.content,
    }));
    messages.push({ role: "user", content: userContent });

    const { text } = await generateText({
      model,
      system: buildSystemPrompt(),
      messages,
      tools: getChatTools(),
      toolChoice: "auto",
      stopWhen: stepCountIs(5),
    });

    return {
      success: true,
      message: {
        id: `msg_${Date.now()}`,
        role: "assistant",
        content: text,
        timestamp: Date.now(),
      },
    };
  } catch (error) {
    return {
      success: false,
      error: error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
    };
  }
}

/** OpenAI í”„ë¡œë°”ì´ë”ì˜ API í‚¤ ìƒíƒœì™€ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ */
export function getProviderStatuses(): ProviderStatus[] {
  return [
    {
      provider: "openai",
      label: "OpenAI",
      available: !!process.env[ENV_KEY],
      models: MODELS,
    },
  ];
}
